{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ivH7lTYjRrNc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dgQrFve8RrNf",
        "outputId": "0f6bc484-0031-417b-8273-94431a22665d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Feedback Sentiment\n",
              "0                        Good case, Excellent value.  Positive\n",
              "1                             Great for the jawbone.  Positive\n",
              "2  Tied to charger for conversations lasting more...  Negative\n",
              "3                                  The mic is great.  Positive\n",
              "4  I have to jiggle the plug to get it to line up...  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19218c1b-abe4-467b-a05f-736c7885add2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feedback</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have to jiggle the plug to get it to line up...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19218c1b-abe4-467b-a05f-736c7885add2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19218c1b-abe4-467b-a05f-736c7885add2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19218c1b-abe4-467b-a05f-736c7885add2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df = pd.read_excel(\"amazonLabelled.xlsx\")\n",
        "df = df[['Feedback','Sentiment']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDnbOERYRrNg"
      },
      "source": [
        "Performing Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2fqz-zmRrNh",
        "outputId": "445e571b-a2aa-4ae8-b372-f76e46b7b52f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Feedback     0\n",
              "Sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd5ZMJmDRrNi",
        "outputId": "e5bfc827-e5cf-457d-8b13-27e4618ed54c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "KhATzEz1RrNi",
        "outputId": "ef421f73-95b6-410b-fed8-51439e731b7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Feedback Sentiment\n",
              "count             999       999\n",
              "unique            989         2\n",
              "top     Great phone!.  Positive\n",
              "freq                2       500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bd5dfd5-a51b-4288-b278-edb1409dcaa2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feedback</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>999</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>989</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Great phone!.</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bd5dfd5-a51b-4288-b278-edb1409dcaa2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bd5dfd5-a51b-4288-b278-edb1409dcaa2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bd5dfd5-a51b-4288-b278-edb1409dcaa2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4nCzRgcRrNj",
        "outputId": "e6ea41ac-d200-4a55-ab8f-e57701cae5f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive    500\n",
              "Negative    499\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "df['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU9ug9EyRrNj"
      },
      "source": [
        "Converting the categorical date in numberical data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QciyvgqDRrNk",
        "outputId": "19e1df37-3dc0-488d-9a36-ed4d4a572168"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Feedback  Sentiment\n",
              "0                        Good case, Excellent value.          1\n",
              "1                             Great for the jawbone.          1\n",
              "2  Tied to charger for conversations lasting more...          0\n",
              "3                                  The mic is great.          1\n",
              "4  I have to jiggle the plug to get it to line up...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84e85fed-ebb7-45f1-87f3-6023590051e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feedback</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have to jiggle the plug to get it to line up...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84e85fed-ebb7-45f1-87f3-6023590051e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84e85fed-ebb7-45f1-87f3-6023590051e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84e85fed-ebb7-45f1-87f3-6023590051e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "df['Sentiment'] = lb.fit_transform(df['Sentiment'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qCW7a_ERrNl"
      },
      "source": [
        "CLeaning the 'TEXT' and Applying lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kiwwqeDuRrNl"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c5JD_bBRrNm",
        "outputId": "d873d2fa-5169-4463-a388-9e94b1c3a2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "wordnet = WordNetLemmatizer()\n",
        "Feedback = []\n",
        "x=df['Feedback']\n",
        "for i in range (len(x)):\n",
        "    feedback = re.sub(\"[^a-zA-Z]\",\" \",x[i])\n",
        "    feedback = feedback.lower()\n",
        "    feedback = feedback.split()\n",
        "    feedback = [wordnet.lemmatize(word) for word in feedback if word not in set(stopwords.words(\"english\"))]\n",
        "    feedback = \" \".join(feedback)\n",
        "    Feedback.append(feedback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_tRnldlvRrNm",
        "outputId": "a93e5d9b-56bd-4fdc-ddb7-e1c3fc8963b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              feedback  Sentiment\n",
              "0                            good case excellent value          1\n",
              "1                                        great jawbone          1\n",
              "2    tied charger conversation lasting minute major...          0\n",
              "3                                            mic great          1\n",
              "4         jiggle plug get line right get decent volume          0\n",
              "..                                                 ...        ...\n",
              "994           screen get smudged easily touch ear face          0\n",
              "995                         piece junk lose call phone          0\n",
              "996                                 item match picture          0\n",
              "997               thing disappoint infra red port irda          0\n",
              "998                      answer call unit never worked          0\n",
              "\n",
              "[999 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-492363f0-e97f-48aa-8441-ec211c6ef505\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feedback</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good case excellent value</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>great jawbone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tied charger conversation lasting minute major...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mic great</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jiggle plug get line right get decent volume</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>screen get smudged easily touch ear face</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>piece junk lose call phone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>item match picture</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>thing disappoint infra red port irda</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>answer call unit never worked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-492363f0-e97f-48aa-8441-ec211c6ef505')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-492363f0-e97f-48aa-8441-ec211c6ef505 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-492363f0-e97f-48aa-8441-ec211c6ef505');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "dt=pd.DataFrame(Feedback,columns=['feedback'])\n",
        "del df[\"Feedback\"]\n",
        "new_df=dt.join(df, how='outer')\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text is the column of feedback\n",
        "text=new_df['feedback'].tolist()\n"
      ],
      "metadata": {
        "id": "J2VNsUa5qAIM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we assign a variable to Sentiment\n",
        "y=new_df['Sentiment']"
      ],
      "metadata": {
        "id": "8ljrQxdGqAFw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize all the word present under text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "token=Tokenizer()\n",
        "token.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "2Y5t-OxsqADa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count the individual word that hold unique index\n",
        "vocab_size=len(token.word_index)+1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g91Mf-pmqAA9",
        "outputId": "a2e4cff5-c328-4cb3-9e02-b98393f0adae"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1565"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token.index_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWj5X8MOp_-U",
        "outputId": "ca3aad2a-5d7f-4873-cd82-f5292d6fd925"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'phone', 2: 'great', 3: 'work', 4: 'good', 5: 'product', 6: 'headset', 7: 'quality', 8: 'battery', 9: 'sound', 10: 'one', 11: 'well', 12: 'ear', 13: 'use', 14: 'case', 15: 'would', 16: 'like', 17: 'time', 18: 'get', 19: 'excellent', 20: 'price', 21: 'recommend', 22: 'really', 23: 'problem', 24: 'make', 25: 'best', 26: 'call', 27: 'fit', 28: 'service', 29: 'charger', 30: 'nice', 31: 'love', 32: 'also', 33: 'new', 34: 'item', 35: 'worked', 36: 'money', 37: 'first', 38: 'buy', 39: 'better', 40: 'ever', 41: 'car', 42: 'bluetooth', 43: 'even', 44: 'look', 45: 'easy', 46: 'comfortable', 47: 'bought', 48: 'year', 49: 'reception', 50: 'could', 51: 'used', 52: 'charge', 53: 'poor', 54: 'thing', 55: 'happy', 56: 'purchase', 57: 'waste', 58: 'two', 59: 'made', 60: 'still', 61: 'bad', 62: 'device', 63: 'cell', 64: 'worst', 65: 'far', 66: 'long', 67: 'motorola', 68: 'day', 69: 'life', 70: 'fine', 71: 'camera', 72: 'enough', 73: 'piece', 74: 'got', 75: 'right', 76: 'volume', 77: 'design', 78: 'last', 79: 'hear', 80: 'clear', 81: 'much', 82: 'using', 83: 'plug', 84: 'month', 85: 'picture', 86: 'working', 87: 'screen', 88: 'think', 89: 'people', 90: 'disappointed', 91: 'pretty', 92: 'button', 93: 'week', 94: 'lot', 95: 'terrible', 96: 'say', 97: 'impressed', 98: 'highly', 99: 'hold', 100: 'verizon', 101: 'everything', 102: 'cool', 103: 'wear', 104: 'jabra', 105: 'light', 106: 'take', 107: 'cheap', 108: 'go', 109: 'customer', 110: 'low', 111: 'however', 112: 'amazon', 113: 'unit', 114: 'without', 115: 'talk', 116: 'little', 117: 'never', 118: 'feature', 119: 'feel', 120: 'broke', 121: 'found', 122: 'tried', 123: 'small', 124: 'voice', 125: 'back', 126: 'horrible', 127: 'hand', 128: 'junk', 129: 'minute', 130: 'several', 131: 'went', 132: 'need', 133: 'turn', 134: 'audio', 135: 'dropped', 136: 'loud', 137: 'real', 138: 'end', 139: 'since', 140: 'find', 141: 'big', 142: 'completely', 143: 'earpiece', 144: 'signal', 145: 'software', 146: 'hour', 147: 'internet', 148: 'stay', 149: 'useless', 150: 'company', 151: 'cable', 152: 'nokia', 153: 'quite', 154: 'looking', 155: 'going', 156: 'way', 157: 'bar', 158: 'three', 159: 'simple', 160: 'priced', 161: 'want', 162: 'headphone', 163: 'within', 164: 'received', 165: 'black', 166: 'around', 167: 'drop', 168: 'know', 169: 'perfectly', 170: 'color', 171: 'le', 172: 'side', 173: 'put', 174: 'v', 175: 'every', 176: 'try', 177: 'came', 178: 'crap', 179: 'keep', 180: 'come', 181: 'anyone', 182: 'difficult', 183: 'samsung', 184: 'value', 185: 'conversation', 186: 'line', 187: 'razr', 188: 'original', 189: 'started', 190: 'clip', 191: 'place', 192: 'charging', 193: 'mobile', 194: 'instruction', 195: 'helpful', 196: 'sure', 197: 'sturdy', 198: 'different', 199: 'player', 200: 'arrived', 201: 'quickly', 202: 'expect', 203: 'order', 204: 'definitely', 205: 'free', 206: 'shipping', 207: 'high', 208: 'wife', 209: 'strong', 210: 'pleased', 211: 'job', 212: 'bt', 213: 'kind', 214: 'tool', 215: 'charm', 216: 'awesome', 217: 'overall', 218: 'part', 219: 'range', 220: 'disappointment', 221: 'important', 222: 'return', 223: 'star', 224: 'many', 225: 'old', 226: 'anything', 227: 'couple', 228: 'disappointing', 229: 'belt', 230: 'data', 231: 'especially', 232: 'plastic', 233: 'break', 234: 'another', 235: 'clarity', 236: 'size', 237: 'nothing', 238: 'hard', 239: 'always', 240: 'replace', 241: 'none', 242: 'cannot', 243: 'connection', 244: 'easily', 245: 'mic', 246: 'decent', 247: 'contact', 248: 'sending', 249: 'must', 250: 'blue', 251: 'absolutely', 252: 'pocket', 253: 'pc', 254: 'left', 255: 'hate', 256: 'kept', 257: 'performance', 258: 'mp', 259: 'seems', 260: 'keyboard', 261: 'actually', 262: 'support', 263: 'later', 264: 'choice', 265: 'purchased', 266: 'bargain', 267: 'plan', 268: 'fall', 269: 'leather', 270: 'fast', 271: 'comfortably', 272: 'set', 273: 'glad', 274: 'obviously', 275: 'noise', 276: 'able', 277: 'lightweight', 278: 'expected', 279: 'mistake', 280: 'worth', 281: 'either', 282: 'drain', 283: 'unreliable', 284: 'family', 285: 'seller', 286: 'plantronics', 287: 'buying', 288: 'weak', 289: 'lg', 290: 'suck', 291: 'ago', 292: 'easier', 293: 'face', 294: 'others', 295: 'wanted', 296: 'deal', 297: 'satisfied', 298: 'rather', 299: 'away', 300: 'unfortunately', 301: 'review', 302: 'palm', 303: 'store', 304: 'cingular', 305: 'ringtones', 306: 'said', 307: 'treo', 308: 'usb', 309: 'extra', 310: 'awful', 311: 'jawbone', 312: 'static', 313: 'though', 314: 'everyone', 315: 'website', 316: 'pair', 317: 'yet', 318: 'run', 319: 'provided', 320: 'included', 321: 'worthless', 322: 'thats', 323: 'protection', 324: 'instead', 325: 'e', 326: 'second', 327: 'complaint', 328: 'perhaps', 329: 'seriously', 330: 'front', 331: 'lock', 332: 'ipod', 333: 'trouble', 334: 'home', 335: 'beautiful', 336: 'longer', 337: 'packaged', 338: 'construction', 339: 'super', 340: 'cost', 341: 'ease', 342: 'play', 343: 'dont', 344: 'decision', 345: 'buyer', 346: 'match', 347: 'flaw', 348: 'display', 349: 'rock', 350: 'number', 351: 'keypad', 352: 'may', 353: 'setup', 354: 'getting', 355: 'almost', 356: 'avoid', 357: 'earbud', 358: 'failed', 359: 'coverage', 360: 'area', 361: 'forever', 362: 'description', 363: 'fantastic', 364: 'w', 365: 'sharp', 366: 'handsfree', 367: 'network', 368: 'slow', 369: 'lost', 370: 'replacement', 371: 'tone', 372: 'extremely', 373: 'simply', 374: 'thought', 375: 'reasonably', 376: 'form', 377: 'experience', 378: 'mess', 379: 'ordered', 380: 'sony', 381: 'market', 382: 'comfort', 383: 'probably', 384: 'poorly', 385: 'charged', 386: 'scratched', 387: 'microphone', 388: 'care', 389: 'lacking', 390: 'uncomfortable', 391: 'plugged', 392: 'flip', 393: 'wireless', 394: 'happier', 395: 'trying', 396: 'finally', 397: 'give', 398: 'dead', 399: 'oh', 400: 'effect', 401: 'might', 402: 'q', 403: 'expensive', 404: 'turned', 405: 'wearing', 406: 'computer', 407: 'result', 408: 'cellphone', 409: 'wrong', 410: 'given', 411: 'holster', 412: 'refund', 413: 'touch', 414: 'speaker', 415: 'sprint', 416: 'needed', 417: 'plus', 418: 'pay', 419: 'tinny', 420: 'pairing', 421: 'video', 422: 'iphone', 423: 'despite', 424: 'outlet', 425: 'cut', 426: 'beep', 427: 'lasting', 428: 'dozen', 429: 'wasted', 430: 'extended', 431: 'notice', 432: 'tooth', 433: 'advise', 434: 'fire', 435: 'owned', 436: 'pull', 437: 'earphone', 438: 'unusable', 439: 'least', 440: 'book', 441: 'regarding', 442: 'returned', 443: 'pda', 444: 'gadget', 445: 'large', 446: 'essentially', 447: 'forget', 448: 'tech', 449: 'particular', 450: 'party', 451: 'clearly', 452: 'cover', 453: 'let', 454: 'died', 455: 'glass', 456: 'sometimes', 457: 'series', 458: 'quiet', 459: 'person', 460: 'saying', 461: 'docking', 462: 'station', 463: 'advertised', 464: 'handy', 465: 'cheaper', 466: 'music', 467: 'beware', 468: 'pro', 469: 'white', 470: 'huge', 471: 'unless', 472: 'although', 473: 'impressive', 474: 'resolution', 475: 'ask', 476: 'slim', 477: 'sex', 478: 'sleek', 479: 'full', 480: 'unhappy', 481: 'done', 482: 'basically', 483: 'careful', 484: 'logitech', 485: 'stuff', 486: 'house', 487: 'recognition', 488: 'tremendous', 489: 'experienced', 490: 'literally', 491: 'stated', 492: 'hoping', 493: 'blackberry', 494: 'technology', 495: 'wired', 496: 'message', 497: 'previous', 498: 'superb', 499: 'communication', 500: 'maintain', 501: 'c', 502: 'graphic', 503: 'thank', 504: 'igo', 505: 'tip', 506: 'option', 507: 'connected', 508: 'h', 509: 'storage', 510: 'buzzing', 511: 'override', 512: 'functionality', 513: 'incredible', 514: 'ring', 515: 'dropping', 516: 'thin', 517: 'nearly', 518: 'bother', 519: 'room', 520: 'issue', 521: 'felt', 522: 'embarrassing', 523: 'consumer', 524: 'background', 525: 'certainly', 526: 'usually', 527: 'bit', 528: 'tell', 529: 'excited', 530: 'additional', 531: 'gel', 532: 'whatsoever', 533: 'purpose', 534: 'secure', 535: 'appears', 536: 'smell', 537: 'caused', 538: 'flimsy', 539: 'flawlessly', 540: 'whole', 541: 'adorable', 542: 'wise', 543: 'gotten', 544: 'driving', 545: 'dialing', 546: 'cant', 547: 'neither', 548: 'game', 549: 'recharge', 550: 'cradle', 551: 'save', 552: 'along', 553: 'start', 554: 'ringing', 555: 'reason', 556: 'auto', 557: 'push', 558: 'skype', 559: 'shipped', 560: 'exactly', 561: 'waiting', 562: 'stupid', 563: 'noticed', 564: 'att', 565: 'model', 566: 'warning', 567: 'dying', 568: 'alone', 569: 'install', 570: 'purchasing', 571: 'moto', 572: 'figure', 573: 'key', 574: 'pad', 575: 'reading', 576: 'sunglass', 577: 'returning', 578: 'procedure', 579: 'cumbersome', 580: 'vx', 581: 'switch', 582: 'worthwhile', 583: 'understand', 584: 'user', 585: 'friendly', 586: 'ability', 587: 'receiving', 588: 'exchanged', 589: 'described', 590: 'im', 591: 'defective', 592: 'unacceptable', 593: 'catching', 594: 'function', 595: 'amazed', 596: 'timeframe', 597: 'source', 598: 'ended', 599: 'accidentally', 600: 'listening', 601: 'window', 602: 'took', 603: 'eargels', 604: 'seem', 605: 'numerous', 606: 'please', 607: 'barely', 608: 'joke', 609: 'forced', 610: 'stop', 611: 'adapter', 612: 'holding', 613: 'broken', 614: 'breaking', 615: 'coming', 616: 'quick', 617: 'operate', 618: 'paired', 619: 'beat', 620: 'brand', 621: 'red', 622: 'echo', 623: 'wind', 624: 'told', 625: 'warranty', 626: 'something', 627: 'placed', 628: 'loop', 629: 'spring', 630: 'download', 631: 'access', 632: 'third', 633: 'flash', 634: 'chinese', 635: 'crisp', 636: 'accept', 637: 'allows', 638: 'open', 639: 'r', 640: 'power', 641: 'wall', 642: 'etc', 643: 'show', 644: 'next', 645: 'carry', 646: 'protector', 647: 'date', 648: 'bottom', 649: 'sounded', 650: 'together', 651: 'foot', 652: 'send', 653: 'current', 654: 'answer', 655: 'laptop', 656: 'inside', 657: 'normal', 658: 'making', 659: 'fails', 660: 'lose', 661: 'ok', 662: 'rest', 663: 'control', 664: 'wow', 665: 'tied', 666: 'major', 667: 'jiggle', 668: 'hundred', 669: 'imagine', 670: 'fun', 671: 'owner', 672: 'needle', 673: 'seperated', 674: 'mere', 675: 'ft', 676: 'excessive', 677: 'garbled', 678: 'odd', 679: 'fooled', 680: 'click', 681: 'wonder', 682: 'mechanism', 683: 'followed', 684: 'direction', 685: 'kindle', 686: 'loved', 687: 'commercial', 688: 'misleading', 689: 'mother', 690: 'combination', 691: 'couldnt', 692: 'breakage', 693: 'unacceptible', 694: 'ideal', 695: 'whose', 696: 'sensitive', 697: 'moving', 698: 'freeway', 699: 'speed', 700: 'contract', 701: 'ac', 702: 'juice', 703: 'highy', 704: 'recommended', 705: 'min', 706: 'short', 707: 'pic', 708: 'garbage', 709: 'mind', 710: 'gonna', 711: 'arguing', 712: 'bulky', 713: 'usable', 714: 'world', 715: 'useful', 716: 'machine', 717: 'neat', 718: 'reasonable', 719: 'stream', 720: 'submerged', 721: 'microsoft', 722: 'faceplate', 723: 'elegant', 724: 'angle', 725: 'drawback', 726: 'pause', 727: 'skip', 728: 'song', 729: 'activated', 730: 'suddenly', 731: 'situation', 732: 'bmw', 733: 'fairly', 734: 'hearing', 735: 'wrongly', 736: 'everyday', 737: 'intended', 738: 'boy', 739: 'load', 740: 'greater', 741: 'bud', 742: 'waaay', 743: 'bluetooths', 744: 'listener', 745: 'integrated', 746: 'seamlessly', 747: 'flush', 748: 'toilet', 749: 'supposedly', 750: 'apparently', 751: 'style', 752: 'correctly', 753: 'rated', 754: 'megapixels', 755: 'render', 756: 'image', 757: 'expectation', 758: 'relatively', 759: 'purcashed', 760: 'geeky', 761: 'toast', 762: 'ooze', 763: 'embedded', 764: 'stylish', 765: 'compromise', 766: 'qwerty', 767: 'basic', 768: 'winner', 769: 'u', 770: 'simpler', 771: 'iam', 772: 'disapoinment', 773: 'realize', 774: 'accompanied', 775: 'brilliant', 776: 'nicely', 777: 'damage', 778: 'definitly', 779: 'majority', 780: 'peachy', 781: 'keen', 782: 'upstairs', 783: 'basement', 784: 'reccomendation', 785: 'relative', 786: 'sudden', 787: 'linking', 788: 'curve', 789: 'funny', 790: 'seemed', 791: 'sketchy', 792: 'web', 793: 'browsing', 794: 'significantly', 795: 'faster', 796: 'build', 797: 'unlike', 798: 'whine', 799: 'communicate', 800: 'monkey', 801: 'share', 802: 'dna', 803: 'copy', 804: 'human', 805: 'bougth', 806: 'l', 807: 'mode', 808: 'wasting', 809: 'file', 810: 'browser', 811: 'offer', 812: 'whether', 813: 'latest', 814: 'o', 815: 'g', 816: 'crawl', 817: 'recognizes', 818: 'bluetoooth', 819: 'thorn', 820: 'abhor', 821: 'recently', 822: 'disconnected', 823: 'buck', 824: 'check', 825: 'mail', 826: 'night', 827: 'backlight', 828: 'lately', 829: 'wit', 830: 'hit', 831: 'weight', 832: 'hardly', 833: 'pleather', 834: 'deaf', 835: 'prettier', 836: 'incredibly', 837: 'investment', 838: 'strange', 839: 'ticking', 840: 'electronics', 841: 'available', 842: 'fm', 843: 'transmitter', 844: 'mega', 845: 'pixel', 846: 'transmit', 847: 'contacting', 848: 'dollar', 849: 'learned', 850: 'lesson', 851: 'online', 852: 'anyway', 853: 'earbugs', 854: 'mean', 855: 'roam', 856: 'living', 857: 'crack', 858: 'infatuated', 859: 'freeze', 860: 'frequently', 861: 'mostly', 862: 'child', 863: 'tick', 864: 'headband', 865: 'hair', 866: 'ericsson', 867: 'favorite', 868: 'authentic', 869: 'shine', 870: 'cute', 871: 'calendar', 872: 'sync', 873: 'defeat', 874: 'penny', 875: 'wallet', 876: 'type', 877: 'excrutiatingly', 878: 'aspect', 879: 'glove', 880: 'durable', 881: 'gosh', 882: 'attractive', 883: 'factor', 884: 'rubber', 885: 'petroleum', 886: 'unbearable', 887: 'scary', 888: 'stereo', 889: 'absolutel', 890: 'potentially', 891: 'fry', 892: 'giving', 893: 'gave', 894: 'reversible', 895: 'rotating', 896: 'contstruct', 897: 'hinge', 898: 'installed', 899: 'overnite', 900: 'thru', 901: 'handset', 902: 'cat', 903: 'attacked', 904: 'protective', 905: 'strip', 906: 'destroying', 907: 'razor', 908: 'someone', 909: 'shouldve', 910: 'invented', 911: 'sooner', 912: 'engineered', 913: 'clever', 914: 'complained', 915: 'tracfone', 916: 'manual', 917: 'alarm', 918: 'clock', 919: 'removing', 920: 'antena', 921: 'compared', 922: 'compliment', 923: 'state', 924: 'allow', 925: 'usage', 926: 'immediately', 927: 'ngage', 928: 'earbuds', 929: 'riingtones', 930: 'rip', 931: 'frequentyly', 932: 'adhesive', 933: 'inexpensive', 934: 'practically', 935: 'add', 936: 'boost', 937: 'concrete', 938: 'knock', 939: 'wood', 940: 'transformed', 941: 'organizational', 942: 'capability', 943: 'sitting', 944: 'vehicle', 945: 'jerk', 946: 'los', 947: 'angeles', 948: 'starter', 949: 'loudspeaker', 950: 'bumper', 951: 'appealing', 952: 'improve', 953: 'leak', 954: 'hot', 955: 'according', 956: 'called', 957: 'applifies', 958: 'specially', 959: 'transmission', 960: 'finished', 961: 'drivng', 962: 'reverse', 963: 'tape', 964: 'embarassing', 965: 'hurt', 966: 'protects', 967: 'average', 968: 'operates', 969: 'soyo', 970: 'self', 971: 'portrait', 972: 'outside', 973: 'exterior', 974: 'mentioned', 975: 'magical', 976: 'help', 977: 'promptly', 978: 'comparably', 979: 'offering', 980: 'today', 981: 'encourage', 982: 'effective', 983: 'recieve', 984: 'prompt', 985: 'kit', 986: 'excelent', 987: 'cingulair', 988: 'nicer', 989: 'era', 990: 'colored', 991: 'hoursthe', 992: 'thereplacement', 993: 'cheaply', 994: 'distorted', 995: 'yell', 996: 'forgot', 997: 'mention', 998: 'weird', 999: 'iriver', 1000: 'spinn', 1001: 'fond', 1002: 'magnetic', 1003: 'strap', 1004: 'psyched', 1005: 'appointment', 1006: 'note', 1007: 'appearance', 1008: 'bland', 1009: 'sanyo', 1010: 'survived', 1011: 'blacktop', 1012: 'ill', 1013: 'enter', 1014: 'modest', 1015: 'cellular', 1016: 'wish', 1017: 'awsome', 1018: 'drained', 1019: 'earpad', 1020: 'displeased', 1021: 'defect', 1022: 'risk', 1023: 'built', 1024: 'restored', 1025: 'jx', 1026: 'searched', 1027: 'lit', 1028: 'portable', 1029: 'colleague', 1030: 'fully', 1031: 'bed', 1032: 'wi', 1033: 'fi', 1034: 'morning', 1035: 'memory', 1036: 'card', 1037: 'hat', 1038: 'timely', 1039: 'shipment', 1040: 'solid', 1041: 'surefire', 1042: 'gx', 1043: 'remorse', 1044: 'accessoryone', 1045: 'inexcusable', 1046: 'changing', 1047: 'carrier', 1048: 'tmobile', 1049: 'update', 1050: 'motorolas', 1051: 'delivery', 1052: 'env', 1053: 'rocketed', 1054: 'destination', 1055: 'unknown', 1056: 'condition', 1057: 'usefulness', 1058: 'bill', 1059: 'pricing', 1060: 'overnight', 1061: 'regret', 1062: 'pitiful', 1063: 'respect', 1064: 'stuck', 1065: 'max', 1066: 'mute', 1067: 'hybrid', 1068: 'palmtop', 1069: 'excels', 1070: 'role', 1071: 'liked', 1072: 'bose', 1073: 'cancelling', 1074: 'amazing', 1075: 'nyc', 1076: 'commuter', 1077: 'photo', 1078: 'ad', 1079: 'earlier', 1080: 'noted', 1081: 'happens', 1082: 'frog', 1083: 'eye', 1084: 'pushed', 1085: 'aluminum', 1086: 'protected', 1087: 'handheld', 1088: 'sturdiness', 1089: 'waterproof', 1090: 'standard', 1091: 'thanks', 1092: 'sliding', 1093: 'edge', 1094: 'pant', 1095: 'ugly', 1096: 'shield', 1097: 'incrediable', 1098: 'improvement', 1099: 'refuse', 1100: 'activate', 1101: 'gentle', 1102: 'threw', 1103: 'inch', 1104: 'kitchen', 1105: 'counter', 1106: 'cracked', 1107: 'laughing', 1108: 'trunk', 1109: 'carried', 1110: 'hitch', 1111: 'practical', 1112: 'ample', 1113: 'channel', 1114: 'directly', 1115: 'increase', 1116: 'properly', 1117: 'missed', 1118: 'sucked', 1119: 'shifting', 1120: 'bubbling', 1121: 'peeling', 1122: 'scratch', 1123: 'droid', 1124: 'zero', 1125: 'exercise', 1126: 'frustration', 1127: 'earset', 1128: 'outgoing', 1129: 'total', 1130: 'package', 1131: 'understanding', 1132: 'patient', 1133: 'wirefly', 1134: 'inform', 1135: 'practice', 1136: 'aggravating', 1137: 'friend', 1138: 'enjoy', 1139: 'virgin', 1140: 'muddy', 1141: 'casing', 1142: 'wire', 1143: 'insert', 1144: 'glued', 1145: 'slid', 1146: 'plantronincs', 1147: 'continues', 1148: 'flawed', 1149: 'disapointing', 1150: 'fourth', 1151: 'hated', 1152: 'fix', 1153: 'accessing', 1154: 'downloading', 1155: 'performing', 1156: 'constantly', 1157: 'due', 1158: 'happening', 1159: 'walked', 1160: 'wiping', 1161: 'strength', 1162: 'louder', 1163: 'constructed', 1164: 'menu', 1165: 'navigate', 1166: 'recessed', 1167: 'avoiding', 1168: 'smoking', 1169: 'linked', 1170: 'effort', 1171: 'possesed', 1172: 'idea', 1173: 'trash', 1174: 'research', 1175: 'development', 1176: 'division', 1177: 'killer', 1178: 'course', 1179: 'infuriating', 1180: 'walkman', 1181: 'europe', 1182: 'asia', 1183: 'clipping', 1184: 'deffinitely', 1185: 'cent', 1186: 'behing', 1187: 'comfortible', 1188: 'pain', 1189: 'arrival', 1190: 'fraction', 1191: 'crappy', 1192: 'seeen', 1193: 'stopped', 1194: 'interface', 1195: 'decade', 1196: 'compete', 1197: 'transceiver', 1198: 'steer', 1199: 'genuine', 1200: 'replacementr', 1201: 'pen', 1202: 'pack', 1203: 'buyit', 1204: 'finger', 1205: 'believe', 1206: 'steep', 1207: 'point', 1208: 'normally', 1209: 'apart', 1210: 'haul', 1211: 'dissapointing', 1212: 'originally', 1213: 'discarded', 1214: 'posted', 1215: 'detailed', 1216: 'comment', 1217: 'grey', 1218: 'guess', 1219: 'existing', 1220: 'cd', 1221: 'surprised', 1222: 'fabulous', 1223: 'currently', 1224: 'shooter', 1225: 'delay', 1226: 'bitpim', 1227: 'program', 1228: 'transfer', 1229: 'accessory', 1230: 'manufacturer', 1231: 'performed', 1232: 'muffled', 1233: 'incoming', 1234: 'severe', 1235: 'resistant', 1236: 'overly', 1237: 'contacted', 1238: 'produce', 1239: 'receipt', 1240: 'luck', 1241: 'linksys', 1242: 'exchange', 1243: 'refurb', 1244: 'snug', 1245: 'heavy', 1246: 'falling', 1247: 'utter', 1248: 'promised', 1249: 'tiny', 1250: 'four', 1251: 'latch', 1252: 'visor', 1253: 'address', 1254: 'reboots', 1255: 'rate', 1256: 'tungsten', 1257: 'flipphones', 1258: 'designed', 1259: 'smoothly', 1260: 'study', 1261: 'interested', 1262: 'sin', 1263: 'industrial', 1264: 'happened', 1265: 'tracking', 1266: 'detachable', 1267: 'continue', 1268: 'periodically', 1269: 'somehow', 1270: 'upload', 1271: 'randomly', 1272: 'locked', 1273: 'truly', 1274: 'worn', 1275: 'ringer', 1276: 'acceptable', 1277: 'balance', 1278: 'ready', 1279: 'prime', 1280: 'upbeat', 1281: 'forgery', 1282: 'abound', 1283: 'explain', 1284: 'jack', 1285: 'ca', 1286: 'smallest', 1287: 'biggest', 1288: 'superfast', 1289: 'ergonomic', 1290: 'theory', 1291: 'stand', 1292: 'occupied', 1293: 'distracting', 1294: 'entire', 1295: 'except', 1296: 'cbr', 1297: 'preferably', 1298: 'ripped', 1299: 'medium', 1300: 'shot', 1301: 'so', 1302: 'connect', 1303: 'mini', 1304: 'near', 1305: 'allowing', 1306: 'startac', 1307: 'regretted', 1308: 'outperform', 1309: 'china', 1310: 'sim', 1311: 'crashed', 1312: 'replaced', 1313: 'quit', 1314: 'connecting', 1315: 'multiple', 1316: 'imac', 1317: 'external', 1318: 'elsewhere', 1319: 'bell', 1320: 'whistle', 1321: 'mediocre', 1322: 'via', 1323: 'slide', 1324: 'grip', 1325: 'prevents', 1326: 'slipping', 1327: 'span', 1328: 'exclaim', 1329: 'whoa', 1330: 'tv', 1331: 'corded', 1332: 'freedom', 1333: 'passed', 1334: 'mark', 1335: 'sign', 1336: 'functional', 1337: 'soft', 1338: 'tight', 1339: 'shape', 1340: 'copier', 1341: 'sent', 1342: 'anywhere', 1343: 'sold', 1344: 'provides', 1345: 'classy', 1346: 'krussel', 1347: 'tracfonewebsite', 1348: 'toactivate', 1349: 'texas', 1350: 'dit', 1351: 'mainly', 1352: 'soon', 1353: 'whatever', 1354: 'blueant', 1355: 'supertooth', 1356: 'metro', 1357: 'sch', 1358: 'slider', 1359: 'premium', 1360: 'plenty', 1361: 'capacity', 1362: 'confortable', 1363: 'somewhat', 1364: 'period', 1365: 'ant', 1366: 'hey', 1367: 'pleasantly', 1368: 'suprised', 1369: 'dustpan', 1370: 'indoors', 1371: 'disposable', 1372: 'puff', 1373: 'smoke', 1374: 'convenient', 1375: 'ride', 1376: 'smoother', 1377: 'nano', 1378: 'son', 1379: 'dissapointed', 1380: 'reccommend', 1381: 'highest', 1382: 'anti', 1383: 'glare', 1384: 'smartphone', 1385: 'wont', 1386: 'atleast', 1387: 'addition', 1388: 'reoccure', 1389: 'somewhere', 1390: 'else', 1391: 'creak', 1392: 'wooden', 1393: 'floor', 1394: 'apartment', 1395: 'generally', 1396: 'inconspicuous', 1397: 'boot', 1398: 'slowly', 1399: 'sorry', 1400: 'impossible', 1401: 'refused', 1402: 'upgrade', 1403: 'discount', 1404: 'securly', 1405: 'possibility', 1406: 'double', 1407: 'booking', 1408: 'entertainment', 1409: 'management', 1410: 'activesync', 1411: 'optimal', 1412: 'synchronization', 1413: 'disgusting', 1414: 'coupon', 1415: 'rare', 1416: 'instance', 1417: 'perfect', 1418: 'p', 1419: 'five', 1420: 'cheapy', 1421: 'talking', 1422: 'shouting', 1423: 'telephone', 1424: 'yes', 1425: 'shiny', 1426: 'grtting', 1427: 'thumb', 1428: 'exceeds', 1429: 'sight', 1430: 'improper', 1431: 'checked', 1432: 'everywhere', 1433: 'ordering', 1434: 'awkward', 1435: 'hoped', 1436: 'father', 1437: 'intermittently', 1438: 'reaching', 1439: 'row', 1440: 'nightmare', 1441: 'describe', 1442: 'speakerphone', 1443: 'cassette', 1444: 'planning', 1445: 'dirty', 1446: 'read', 1447: 'sensor', 1448: 'reliability', 1449: 'beeping', 1450: 'letting', 1451: 'dieing', 1452: 'ir', 1453: 'cancellation', 1454: 'counterfeit', 1455: 'see', 1456: 'travled', 1457: 'swivel', 1458: 'sister', 1459: 'dual', 1460: 'keeping', 1461: 'bottowm', 1462: 'gimmick', 1463: 'top', 1464: 'causing', 1465: 'discomfort', 1466: 'trust', 1467: 'maintains', 1468: 'flawless', 1469: 'utterly', 1470: 'confusing', 1471: 'holder', 1472: 'cutout', 1473: 'land', 1474: 'material', 1475: 'exceptional', 1476: 'owning', 1477: 'official', 1478: 'oem', 1479: 'loudest', 1480: 'setting', 1481: 'competitor', 1482: 'saved', 1483: 'alot', 1484: 'totally', 1485: 'unintelligible', 1486: 'word', 1487: 'restart', 1488: 'managed', 1489: 'bend', 1490: 'leaf', 1491: 'metal', 1492: 'stress', 1493: 'leopard', 1494: 'print', 1495: 'wonderfully', 1496: 'wild', 1497: 'saggy', 1498: 'floppy', 1499: 'loos', 1500: 'snap', 1501: 'fliptop', 1502: 'loose', 1503: 'wobbly', 1504: 'eventually', 1505: 'receive', 1506: 'seat', 1507: 'fulfills', 1508: 'requirement', 1509: 'fact', 1510: 'lightly', 1511: 'rating', 1512: 'lap', 1513: 'accessable', 1514: 'mine', 1515: 'christmas', 1516: 'otherwise', 1517: 'joy', 1518: 'satisifed', 1519: 'spec', 1520: 'armband', 1521: 'allot', 1522: 'clearer', 1523: 'reach', 1524: 'ericson', 1525: 'z', 1526: 'motor', 1527: 'center', 1528: 'voltage', 1529: 'humming', 1530: 'equipment', 1531: 'certain', 1532: 'girl', 1533: 'complain', 1534: 'wake', 1535: 'styling', 1536: 'restocking', 1537: 'fee', 1538: 'darn', 1539: 'lousy', 1540: 'seen', 1541: 'sweetest', 1542: 'securely', 1543: 'hook', 1544: 'directed', 1545: 'canal', 1546: 'unsatisfactory', 1547: 'negatively', 1548: 'provide', 1549: 'hype', 1550: 'assumed', 1551: 'lense', 1552: 'covered', 1553: 'text', 1554: 'messaging', 1555: 'tricky', 1556: 'painful', 1557: 'lasted', 1558: 'blew', 1559: 'flop', 1560: 'smudged', 1561: 'disappoint', 1562: 'infra', 1563: 'port', 1564: 'irda'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#From the indexed word now it assign index for each sentences\n",
        "encoded_text=token.texts_to_sequences(text)\n",
        "print(encoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnz8Na1-p_73",
        "outputId": "ad65b23c-2620-4ce4-d35f-2a8d2e98985f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 14, 19, 184], [2, 311], [665, 29, 185, 427, 129, 666, 23], [245, 2], [667, 83, 18, 186, 75, 18, 246, 76], [130, 428, 130, 668, 247, 669, 670, 248, 10, 10], [187, 671, 249], [672, 96, 429, 36], [57, 36, 17], [9, 7, 2], [97, 155, 188, 8, 430, 8], [58, 673, 674, 675, 189, 431, 676, 312, 677, 9, 6], [4, 7, 313], [77, 678, 12, 190, 46], [98, 21, 10, 250, 432, 1], [433, 314, 679], [65, 4], [3, 2], [680, 191, 156, 24, 681, 66, 682, 15, 78], [131, 67, 315, 683, 684, 50, 18, 316], [47, 13, 685, 434, 251, 686], [687, 688], [317, 318, 33, 8, 58, 157, 158, 68, 114, 192], [47, 689, 23, 8], [2, 252, 253, 1, 690], [435, 1, 84, 96, 25, 193, 1], [88, 194, 319, 195], [89, 691, 79, 115, 436, 437, 115, 1], [99, 52], [159, 116, 1, 13, 692, 693], [5, 694, 89, 16, 695, 12, 696], [438, 697, 41, 698, 699], [58, 48, 254, 700, 255, 1], [41, 29, 11, 701, 29, 320, 24, 196, 117, 318, 702, 703, 704], [132, 439, 705, 18, 1, 440, 17, 37, 133, 1, 8, 69, 706], [256, 11], [53, 115, 17, 257], [14, 2, 3, 70], [321, 5], [2, 71, 322, 258, 707, 30, 80, 2, 85, 7], [97, 5], [30, 6, 160, 75], [79, 708, 134], [19, 42, 6], [118, 161], [75, 709, 710, 38, 8], [711, 100, 441, 135, 26, 442, 1, 58, 68], [14, 259, 11, 59], [90, 8], [136, 72, 133, 16], [4, 323, 24, 1, 712], [713, 260, 261, 133, 443, 137, 714, 715, 716, 324, 717, 444], [1, 91, 197, 117, 445, 23], [31, 54], [101, 70, 718, 20, 325], [90], [43, 135, 1, 719, 720, 326, 60, 3, 2], [55, 327, 10, 441, 9, 7, 138], [92, 61], [446, 447, 721, 448, 262], [22, 21, 722, 139, 44, 30, 723, 102], [162, 2, 140, 88, 328, 25, 56, 59, 78, 130, 48, 329], [38, 198, 1], [99, 1, 449, 724, 450, 79, 451], [10, 141, 725, 258, 199, 92, 1, 330, 452, 453, 726, 727, 728, 331, 326], [93, 263, 729, 730, 454], [119, 46, 6, 103, 455, 18, 156, 456], [2, 332], [62, 2, 130, 731], [245, 3], [43, 732, 457, 733, 458, 333, 734, 459, 460], [2, 264], [30, 461, 462, 334, 3], [335, 1], [31, 5], [38, 735, 463], [2, 116, 34], [31, 1, 464, 94, 118], [265, 163, 68, 336, 86], [103, 736, 99, 11], [4, 266], [11, 337, 200, 17, 3, 737], [8, 318, 201], [34, 35, 2, 120, 84, 13], [6, 45, 13, 314, 31], [1, 3, 2], [338, 6, 53], [5, 19, 3, 39, 100, 10, 738, 465], [1, 739, 339], [5, 340, 81, 10, 202, 3, 65, 39, 740, 341, 54], [59, 197], [35, 2], [12, 741, 342, 466, 10, 12], [343, 57, 36], [203], [267, 13, 41, 447], [121, 5, 742, 141], [25, 121, 65, 122, 743, 10, 25, 7, 744, 11, 341, 82], [90, 344], [745, 746, 67, 187, 1], [345, 467, 50, 747, 36, 75, 748], [204, 266], [20, 4, 205, 206, 4, 56], [164, 749, 33, 67, 750, 346, 1, 29], [468, 4, 71, 30, 85, 32, 102, 751, 16, 165, 469], [470, 77, 347, 471, 82, 752, 88, 14], [31, 6, 104, 42, 6, 2, 49, 4, 12, 73, 46, 27], [71, 472, 753, 473, 754, 755, 756, 268, 11, 757, 758, 207, 474], [759, 41, 29, 3], [9, 7, 138, 19, 13, 6, 26, 208, 475, 208, 13, 6, 26], [1, 476, 105, 348, 335], [116, 760, 88, 322, 477, 761, 349, 762, 477, 75, 8, 763, 478, 764, 269, 14], [2, 5, 270, 206], [251, 2], [260, 30, 765, 479, 766, 767, 63, 1, 350, 351], [74, 1, 166, 138, 352, 142, 480], [46, 12], [768, 769], [353, 770], [122, 130, 198, 143, 63, 1, 104, 10, 37, 10, 121, 27, 12, 271], [50, 18, 209, 72, 144], [771, 210, 56], [61, 7], [18, 211, 481], [2, 134], [482, 28, 61], [3, 63, 1, 83, 272, 29], [42, 93, 22, 16], [212, 6, 772], [123, 43, 773, 354, 51], [774, 145, 355, 775], [6, 3, 2, 337, 776, 356, 777], [778, 21], [345, 483], [779, 484, 357, 6, 358], [4, 485, 20], [6, 3, 780, 781], [486, 354, 135, 359, 782, 359, 783], [124, 487, 488], [57], [130, 198, 129, 26, 489, 167, 360, 157], [55, 34], [90], [1, 106, 361, 52, 16, 146, 490], [74, 1, 784, 785, 273], [57, 17], [49, 53], [34, 491, 320, 362, 320], [84, 87, 131, 165, 786], [492], [134, 7, 53, 53], [251, 23, 6, 787, 493, 788], [168, 9, 789, 790, 16, 791, 494, 3, 11, 11, 10, 3, 2], [47, 495, 162, 9, 39], [1, 270, 248, 213, 496, 792, 793, 794, 795, 497, 1, 51], [30, 7, 796, 797, 107], [34, 363, 3, 169], [31, 170], [364, 498], [798, 147, 108, 13, 54, 171, 16], [2, 29], [446, 499, 214, 799], [3, 16, 215, 3, 10, 74, 1], [60, 500, 800, 24, 162, 274, 801, 72, 802, 803, 77, 804], [2, 184], [3, 805, 806, 501, 86], [44, 365, 87, 30, 80, 2, 502], [78, 66], [10, 54, 255, 807, 272, 92, 172], [19, 28], [503, 808, 36], [134, 7, 53], [504, 29, 505, 22, 2], [809, 810, 811, 506, 10, 132, 366, 2], [498, 1, 2, 367], [507, 208, 42, 67, 508, 1, 35, 16, 215, 812, 1, 252, 14], [173, 813, 814, 174, 815, 16, 368, 816, 331, 175], [817, 1, 509, 62], [16, 136, 510, 511, 185, 1], [38, 5], [818, 6, 17, 60, 46, 156, 27, 12], [9, 7, 4, 512, 216], [1, 819, 172, 22, 820], [821, 23, 50, 148, 507, 129, 822], [513], [77, 347], [2, 1], [57, 823], [824, 124, 825, 826, 351, 827, 133, 326, 37, 496, 369], [370, 454, 93], [514, 371, 217, 4, 1, 38], [828, 372, 30, 195, 1], [23, 829, 830, 515, 144], [97], [105, 831, 832, 431], [31, 516], [61, 264], [833, 14, 27], [149, 1, 373, 834], [170, 43, 835, 374, 15, 502, 836, 365], [88, 4, 837], [24, 838, 839, 275, 138, 26], [25, 840, 841, 842, 843], [8, 78, 146], [2, 6, 97, 508], [844, 845, 71, 218, 1, 375, 4], [517, 48, 35, 2], [4, 846, 134], [248, 125], [518, 847, 150, 848, 5, 849, 850, 47, 376, 851, 852], [255, 853, 356, 1, 854], [2, 20, 32], [219, 246, 276, 855, 166, 486, 1, 856, 519, 49, 9, 7, 520], [270, 28], [15, 98, 21], [15, 21], [32, 16, 92, 521, 16, 15, 857, 13], [64, 1, 40], [60, 858, 1], [859, 860], [213, 522, 13, 44, 861, 522, 862, 16, 150], [159, 277, 2, 27], [278, 39, 523, 377, 67], [126, 863, 9, 524, 26, 117, 489], [525, 46, 512, 246], [526, 16, 864, 10, 277, 378, 865], [527, 90], [1, 48, 528, 2], [379, 380, 866, 364, 88, 35, 322, 37, 51], [8, 142, 149], [141, 57, 17], [57, 10], [2, 9, 28], [22, 210, 5, 65], [10, 867, 56, 40], [25, 42, 381], [868, 269, 30, 869, 382, 21, 14], [529, 18, 6, 374, 22, 870], [24, 279], [141, 220, 871, 872], [1, 438, 33], [64, 109, 28, 40], [530, 12, 531, 319, 194, 532], [873, 533, 42, 6], [280, 175, 874], [19, 875, 876, 1, 14], [30, 162, 20, 3, 2], [147, 877, 368], [46, 103, 11, 383, 221, 878, 82, 14], [27, 16, 879, 209, 534, 880], [881, 25, 1, 40], [882, 535, 4, 7], [31, 118, 376, 883], [5, 209, 884, 885, 536, 886, 537, 222], [53, 7, 28], [151, 44, 516, 538, 887], [2, 143], [19, 127, 205, 214], [2, 82, 334, 888], [4, 5, 513, 184], [84, 35, 539, 65], [3, 2], [889, 128], [10, 3, 281], [8, 69, 137, 4], [442, 146, 263], [2, 34], [57, 36], [31, 6], [282, 199, 352, 32, 890, 891], [35, 169], [283, 892], [893, 223, 9, 7], [356, 10], [894, 83, 3, 2], [429, 116, 36, 143], [4, 1], [25, 895, 118, 195], [382, 540, 284], [4, 5, 4, 285], [31, 42], [37, 103, 11], [97, 6, 286], [74, 123, 541], [2, 1], [21, 287, 5], [73, 128], [384, 896, 897], [34, 2, 898, 453, 385, 899, 86, 4, 175, 139, 23], [2, 1], [38], [19, 1], [56, 1], [124, 487, 900, 901, 19], [127, 25, 1, 40], [3, 2, 902, 903, 1, 386, 904, 905, 324, 906, 87], [10, 3, 160, 75], [109, 28, 95], [8, 69, 60, 66, 72, 67, 907, 174], [248, 125], [168, 59, 542, 344], [908, 909, 910, 911], [4, 20], [101, 35, 37, 176, 62, 525, 912, 913, 156, 338, 119, 4], [164, 201, 3, 2], [86, 2], [224, 89, 914, 121, 6, 387, 288], [48, 225, 152, 915, 99, 52, 94, 39], [388, 523, 10, 527], [4, 8, 74, 22, 270], [194, 916, 389], [32, 476, 72, 27, 917, 918, 461, 462, 114, 919, 14], [1, 99, 52, 16, 33], [8, 283, 11, 28, 13, 920], [390, 9, 7, 153, 53, 921, 1, 187, 497, 495, 6, 391, 289], [543, 94, 922], [204, 249, 923, 924, 63, 1, 925, 544], [161, 36, 125], [31, 62], [32, 55, 20], [379, 5, 37, 480, 926], [927, 60, 389, 928], [276, 124, 545, 41, 23], [157, 63, 1, 334, 546, 79, 226], [4, 34, 110, 20], [111, 929, 25, 547, 548], [83, 3, 11], [112, 290], [930, 52, 206], [46], [8, 86, 11, 370, 188, 177, 1, 48, 291], [49, 19], [27, 271, 281, 12, 9, 80, 136, 52, 78, 227, 68], [80, 7, 9, 378, 9, 332, 139, 9, 92, 6], [66, 427, 8, 549, 931, 392, 1], [274, 23, 932], [228], [933, 73, 15, 60, 278, 39, 7], [934, 149, 935, 213, 936, 49, 47], [19, 9, 7], [55], [73, 128, 120, 1, 68], [33, 8, 3, 2, 1], [64, 109, 28], [135, 1, 17, 96, 43, 937, 1, 60, 2, 938, 939], [49, 95, 479, 312], [4, 134, 7], [116, 62, 940, 941, 942, 59, 69, 540, 94, 292], [943, 944, 550, 229, 6, 369, 144], [945, 1], [3, 16, 215, 3, 463], [46, 30, 219, 4, 8, 69], [367, 359, 946, 947, 126], [19, 948, 393, 6], [949, 506, 2, 950, 105, 951], [54, 88, 50, 952, 9, 953, 6], [37, 49, 290, 117, 157, 40], [1, 18, 372, 954], [387, 32, 3, 11, 955, 89, 956, 957, 101], [30, 77, 7], [32, 1, 135, 14, 155, 551, 958, 135, 293], [105, 45, 13, 80, 49, 959], [61, 27, 156, 141], [204, 4], [216, 62], [57, 36], [379, 67, 230, 151, 74, 11, 960, 86, 5], [31, 1], [154, 6, 66, 17, 74, 394], [961, 552, 6, 553, 554, 555], [348, 19, 71, 4, 48], [8, 69, 32, 2], [64, 1, 40, 84], [4, 34, 35, 189, 23, 556, 962, 963, 199], [964, 32, 12, 965, 176, 557, 12, 83, 12], [966, 1, 172], [967, 1, 61, 8, 69, 968, 288, 367], [80, 558, 26, 66, 8, 69, 66, 219], [969, 494, 290], [2, 127, 205, 62], [43, 106, 970, 971, 972, 973, 348, 102], [23, 294, 974], [395, 224, 224, 366, 444, 10, 396, 3, 11], [975, 976], [64, 73, 178, 40, 552, 100, 109, 28], [53, 9, 7], [25, 1, 381], [35, 11], [150, 559, 5, 977, 3, 11], [560, 295], [85, 474, 65, 978, 160, 1, 979, 980], [2, 296], [19, 5, 297, 56], [98, 21, 981, 89, 397, 176], [39, 202], [82, 143, 254, 75, 54, 148, 12], [2, 5, 20], [9, 4, 375, 160, 982, 159], [60, 561, 196, 34, 15, 3, 11, 40, 983], [220], [984, 28], [19, 5, 20], [210, 6], [57, 36, 17], [231, 31, 66, 8, 69], [562, 179, 287, 33, 29, 41, 29, 550, 162, 41, 985, 175, 17, 33, 1, 180], [3, 2], [286, 42, 986, 38], [177, 100, 987, 988, 63, 1, 37, 54, 563, 22, 61, 28], [154, 33, 143], [98, 21, 62, 314], [311, 989, 216], [164, 469, 990, 8, 108, 398, 227, 991, 188, 51, 78, 93, 60, 78, 336, 992], [48, 8, 131, 142, 398, 6], [51, 130, 1, 58, 48, 10, 25], [216, 33, 44, 268], [37, 1, 993, 59], [564, 80, 9, 994, 995, 115], [232, 233, 22, 45, 190], [20, 4], [24, 279], [399, 996, 32, 997, 998, 170, 400, 1], [82, 999, 1000, 14, 27, 70], [32, 360, 113, 120, 1001, 1002, 1003], [217, 1004, 1, 1005, 247, 18, 2, 49], [175, 54, 1, 3, 169, 16], [234, 1006, 1, 1007, 22, 44, 298, 1008, 231, 165, 565], [22, 45], [1009, 1010, 428, 167, 1011, 114, 1012, 400], [363, 437], [140, 63, 1, 75, 299, 1013, 41], [110, 7], [98, 21, 1014, 160, 1015, 1], [18, 39, 49, 235, 1], [566, 148, 299], [1016, 50, 222, 113, 18, 125, 36], [1017, 62, 3, 2], [51, 115, 146, 8, 15, 490, 1018, 567], [140, 61, 113, 180, 10, 1019, 15, 21, 181], [1020], [401, 543, 1021, 15, 1022, 287, 1023, 7, 568], [59, 14, 123, 182, 569], [1024, 1, 16, 33, 257], [15, 21, 570, 104, 1025, 457, 3, 539, 571, 402, 108, 572], [1026, 147, 121, 10, 25, 184], [27], [55, 5], [87, 236, 141, 573, 574, 1027, 11, 72, 71, 7, 19, 71, 1], [22, 237, 61, 96, 6], [273, 121, 5, 112, 238, 140, 207, 160], [1028, 3], [1029, 18, 2, 49, 116, 403, 257, 2], [43, 1030, 385, 131, 1031, 404, 250, 432, 1032, 1033, 563, 254, 1034], [32, 23, 1, 575, 1035, 1036, 239, 133], [4, 405, 1037, 576], [1038, 1039, 7, 5], [30, 1040, 260], [11, 59, 27, 1041, 1042, 169], [126, 1], [212, 8, 128], [15, 21, 294], [546, 18, 145, 3, 406], [90], [53, 124, 235], [8, 3, 2], [345, 1043, 10], [90, 1044], [140, 1045, 383, 577, 1, 328, 1046, 1047], [44, 2, 209], [1048, 28, 48, 91, 55], [1049, 578, 182, 579], [220, 255, 226, 108, 12], [2, 145, 1050], [1051, 17], [45, 13], [390, 12, 13, 289, 580, 1052], [76, 581, 1053, 113, 1054, 1055], [99, 52, 66, 17, 375, 46, 66, 405, 1056, 7, 9, 488], [16, 222], [260, 22, 582, 1057, 197, 72, 202, 23], [100, 1058, 111, 182, 583, 43, 313, 1059, 267, 159], [192, 1060, 8, 3, 2], [1061], [31, 1], [220], [584, 585], [300, 586, 261, 168, 587, 26, 298, 221, 118, 1, 1062, 1063], [588, 1, 43, 23], [407, 1, 281, 1064, 1065, 76, 1066], [443, 349], [339, 385, 13, 123, 1067, 1068, 71, 408, 1069, 1070], [15, 204, 21, 104, 212, 174, 154, 382, 235, 2, 20], [100, 48, 291, 22, 1071, 28], [91, 73, 128], [83, 409, 236], [3, 589], [551, 36, 34, 84], [61, 56], [11, 590, 297], [1072, 275, 1073, 1074, 221, 1075, 1076], [8, 19, 266], [591, 178], [15, 410, 223, 276], [103, 455, 27, 70], [9, 7, 62, 592, 471, 22, 458, 360, 355, 79, 237], [15, 21, 34, 181], [411, 200, 346, 1077, 1078], [2, 23], [1079, 301, 1080, 83, 29, 237, 1081], [1082, 1, 215, 541, 1083, 593], [117, 168, 1084, 238, 72, 75, 350, 17, 594, 161], [9, 80, 89, 115, 595, 7], [74, 1085, 14, 33, 302, 580, 35, 22, 11, 1086, 1087, 169, 65], [4, 5, 11, 59], [193, 1, 214, 249], [97, 211, 67, 1088, 1], [164, 203, 11, 163, 206, 596, 101, 4, 86, 203, 217, 529, 597], [1, 197, 1089], [97, 15, 21, 34, 181], [327, 1090, 9, 76, 116, 110, 43, 404], [1091, 112, 54, 132, 4, 20], [598, 1092, 1093, 1094, 125, 252, 324], [108, 303, 47, 33, 152, 1, 86, 2], [3, 2], [22, 1095], [126, 581, 17], [275, 1096, 1097], [137, 1098], [187, 8, 4, 38], [179, 4, 3, 112], [1099, 412, 240], [300, 45, 599, 1100, 1101, 413, 92, 599, 413, 1, 293, 600], [482, 1102, 36, 601, 237], [2, 14, 20], [602, 10, 167, 1103, 1104, 1105, 1106, 97, 1107], [42, 219, 4, 68, 291, 254, 1, 1108, 74, 26, 1109, 185, 114, 1110], [123, 478, 473, 154, 1111, 353, 1112, 509, 191], [603, 1113, 9, 1114, 12, 604, 1115, 9, 76, 235], [241, 33, 10, 40, 153, 35, 1116], [273, 265], [1117, 605, 26, 555], [328, 1, 591, 89, 242, 79, 13], [38, 5], [1118, 485, 3, 1], [1119, 1120, 1121, 43, 1122, 237, 394, 33, 10, 1123], [64, 145, 40, 51, 50, 397, 1124, 223, 15], [395, 24, 26, 1125, 1126], [14, 538, 73, 232, 330, 172, 323, 532], [104, 1127, 55, 9, 7, 231, 1128, 39], [31, 71, 22, 91, 4, 7], [503, 2, 28], [1129, 1130], [285, 1131, 1132, 15, 204, 38], [397, 1133, 223, 247, 304, 1134, 1135], [1136], [2, 5, 20], [265, 284, 1137, 1138, 235, 341, 13], [1139, 393, 349, 107, 116, 1], [241, 3, 38], [1140, 110, 7, 9, 1141, 166, 1142, 1143, 384, 339, 1144, 1145], [606, 343, 57, 36], [153, 297, 56], [154, 4, 7, 67, 6, 179, 154], [317, 1146, 1147, 13, 1148, 29, 77], [1149, 407], [579, 77], [2, 33, 337, 30, 3, 4, 23, 177, 171, 17, 278], [2, 5], [73, 178], [377, 95, 1150, 42, 6, 81, 46, 78, 104, 1151], [1152, 23], [64, 40], [55], [333, 1153, 147, 1154, 305, 1155, 594], [607, 40, 79, 1156, 460], [8, 69, 98, 592], [150, 608], [101, 362, 306, 15], [1157, 1158, 175, 26, 609, 610, 82, 6], [3, 2, 41, 29, 231, 242, 83, 58, 611, 17], [100, 448, 262, 1159, 578, 241, 35, 598, 238, 272, 1160, 230], [124, 7, 144, 1161, 135, 26], [342, 1162, 414, 236, 20, 110, 15, 88, 7, 389, 111], [39, 278], [119, 384, 1163, 1164, 182, 1165, 92, 1166, 182, 557], [8, 612, 11], [32, 182, 173, 21, 1167, 5], [51, 58, 68, 239, 45, 79], [74, 41, 29, 43, 93, 29, 613, 131, 83, 189, 1168], [415, 95, 109, 28], [1169, 1, 114, 1170], [102], [45, 13], [39, 33], [1171, 18, 128, 1172], [73, 1173], [91, 4, 5], [2, 1], [20, 112, 19, 5, 15, 98, 21], [1174, 1175, 1176, 274, 168], [137, 1177, 76, 1178, 614], [1, 86, 70], [55, 5], [53, 338], [1179], [217, 15, 21, 1, 33, 1180], [415, 52, 28], [107, 119, 44, 107], [27, 12, 11, 46], [3, 1181, 1182], [1183, 229, 1184, 24, 119, 16, 1185, 615], [16, 77, 44, 104, 1186, 12, 6, 91, 1187, 103, 146, 68, 114, 1188, 12], [595, 616, 1189, 58, 188, 289, 63, 1, 8, 1190, 20], [64, 1, 183, 178, 1191, 183, 325, 64, 40, 1192], [29, 35, 93, 142, 1193, 192, 1], [53, 5], [111, 416, 39, 194], [132, 58, 127, 617, 87, 145, 1194, 1195, 225, 242, 1196, 33, 145, 77], [35, 11, 618, 307, 364, 558, 6, 253, 82, 308, 42, 1197], [1198, 80, 5, 108, 1199, 302, 1200, 1201, 180, 158, 1202], [38, 1203, 290], [2, 5, 196, 619, 82, 1204], [417, 329, 1205, 280, 1206, 20, 1207], [14, 122, 1208, 268, 1209, 84, 10, 259, 66, 1210], [1211, 257], [24, 279, 606, 38, 1], [1, 401, 11, 64, 40, 620], [14, 171, 309, 1212, 173, 263, 1213, 386, 12], [21, 504, 181, 198, 620, 63, 1, 258, 199, 284], [518, 108, 303], [1214, 1215, 1216, 1217, 165, 1, 434, 621, 2, 170], [23, 34, 15, 203, 416], [18, 418, 1218], [145, 2, 211, 50, 32, 24, 305, 376, 1219, 1220, 114, 147, 243], [590, 1221, 4, 7, 41, 29, 81, 301], [1222], [111, 212, 6, 1223, 4, 137, 17, 548, 16, 37, 459, 1224, 139, 134, 1225, 378], [51, 1226, 205, 1227, 140, 147, 1228, 230, 1, 20, 151, 19], [228, 1229, 4, 1230], [1231, 310, 1232, 419, 1233, 9, 1234, 622, 138, 26], [623, 1235], [274, 95, 109, 28, 18, 418], [78, 361, 1236, 403, 240, 45, 617, 9, 81, 39, 294, 122], [1237, 150, 624, 472, 113, 60, 625, 1238, 1239, 1240], [1241, 156, 1242, 61, 1, 1243, 113, 626], [1, 197, 152, 157, 1], [2, 1], [627, 307, 14, 1244, 94, 309, 519, 172], [210], [8, 95], [121, 5, 45, 272, 13], [143, 445, 1245, 179, 1246, 12], [1247, 178, 9, 7, 95], [29, 200, 163, 1248, 596, 3], [12, 628, 416, 1249, 9, 2], [396, 158, 1250, 17, 629, 1251, 120, 50, 13, 336, 1252], [366, 218, 3, 70, 41, 176, 630, 1253, 440, 307, 1254, 217, 60, 1255, 62, 207], [115, 149, 109, 28], [521, 105, 419], [27, 302, 1256, 325, 120, 37, 17, 122, 83], [55, 56, 4, 7, 110, 20], [31, 44, 119, 183, 1257], [11, 1258, 365, 250, 30, 170], [101], [50, 21], [30, 9], [44, 4, 85, 14, 470, 220], [81, 171, 311, 155, 240], [353, 131, 1259], [372, 368, 106, 361, 226], [249, 1260, 181, 1261, 64, 1262, 1263, 77], [37, 54, 1264, 1265], [11, 59, 45, 631, 1, 464, 1266, 229, 190], [1267, 420, 1268, 139, 1269, 256, 515], [1270, 305, 632, 450], [42, 3, 1, 331, 87, 633, 24, 26, 1271, 252, 1272], [1273, 310], [3, 70, 67, 408, 94, 39, 1274, 8], [76, 1275, 137, 4, 264, 136], [241, 371, 1276], [71, 170, 1277, 310], [5, 451, 1278, 1279, 17, 388, 102, 44, 528, 26, 615, 321], [31, 305, 1280], [634, 1281, 1282], [45, 316, 183, 63], [194, 1283, 387, 1284, 50, 51], [15, 433, 56, 34, 117, 35, 11], [61, 418, 84, 28], [3, 11], [152, 1285, 308, 151, 3, 1], [80, 635, 9], [13, 1286, 143, 319, 148, 91, 11], [1287, 327, 8, 282, 1288], [77, 401, 1289, 1290, 50, 1291, 12], [38, 161, 13, 411], [1, 32, 106, 2, 85, 43, 421, 190], [24, 44, 102], [12, 1292, 524, 1293], [46, 27, 132, 6, 46, 439, 146, 17, 1294, 68], [32, 1, 604, 636, 226, 1295, 1296, 258, 1297, 1298, 601, 1299, 199], [619, 20], [180, 209, 105, 13, 105, 71, 1300, 43, 633, 1301, 144, 329], [277, 3, 11], [467], [31, 151, 637, 1302, 1303, 308, 62, 253], [181, 1304, 79, 218, 185], [102, 14, 638, 1305, 87, 18, 386], [47, 1, 370, 1306, 1307, 139], [535, 261, 1308, 188, 8, 1309, 177, 174], [303, 226, 1, 350, 1310], [78, 171, 129, 261, 176, 13, 1, 208, 1, 23], [53, 7], [104, 12, 531, 639, 25], [280], [1, 1311, 142, 18, 1312], [1313, 86, 51, 84, 265, 234, 10, 25, 6, 40, 435], [300, 549, 422, 423, 1314, 1315, 640, 597, 1316, 1317, 8, 641, 424, 642], [2, 1], [373, 161, 123, 392, 1, 44, 1318, 309, 1319, 1320, 1321], [4, 184, 3, 70, 640, 1322, 308, 41, 641, 424], [1, 1323, 166, 41, 1324, 1325, 1, 1326, 127], [373, 25, 42, 6, 9, 7], [88, 267, 10, 196, 78, 571, 1], [1327, 146, 58, 89, 1328, 1329, 33, 1, 1330], [239, 51, 1331, 6, 1332, 393, 195], [14, 1333, 10, 48, 1334, 643, 1335, 103, 1336], [269, 30, 1337, 27, 1338, 425, 293, 4, 1339], [101, 132, 475], [587, 82, 5, 68, 120], [5, 2, 24, 86, 94, 292, 108, 1340, 561, 99, 626], [241, 158, 236, 1341, 6, 15, 148, 12], [193, 25, 109, 28, 1342], [200, 201, 81, 171, 403, 294, 1343], [122, 113, 358, 163, 84, 468], [1344, 4, 323, 44, 1345], [1346, 239, 4], [1347, 584, 585, 24, 45, 1348, 642], [77, 4], [2, 49, 17], [15, 98, 21, 5], [13, 113, 576, 4, 1349], [1350, 3, 17, 152], [47, 1351, 29, 120, 1352, 570], [16, 136, 510, 511, 185, 1], [363, 38, 18, 1353, 644, 1], [148, 299, 303, 483], [1354, 1355, 127, 205, 1, 414, 216], [27], [34, 200, 201, 3, 2, 1356, 253, 183, 1357, 639, 1358, 1, 380, 1359, 9, 12, 83], [105, 1360, 8, 1361, 1362, 103, 1363, 430, 1364, 17], [228], [250, 1365, 45, 13], [107, 1366, 3, 1367, 1368, 410, 110, 340, 34], [71, 1, 352, 51, 1369, 1370, 298, 82, 1371], [68, 263, 1372, 1373, 177, 1, 13], [1374, 159, 13, 18, 211, 481, 24, 41, 1375, 81, 1376], [1377, 491, 1378, 1379], [9, 7, 19, 11], [25, 6, 51], [15, 1380], [166, 48, 645, 1381, 7, 1382, 1383, 87, 646, 121, 647], [295], [449, 565, 15, 3, 67, 402, 1384], [1385, 3, 75, 1386], [1387, 119, 44, 1, 277, 107, 232], [625, 23, 1388, 648, 186, 173, 36, 1389, 1390, 304, 262], [22, 295, 286, 75, 10, 224, 520, 4], [2, 5], [635, 80], [37, 52, 256, 155, 398, 129], [107, 232, 1391, 16, 225, 1392, 1393], [18, 251, 126, 49, 1394, 1, 23], [49, 1395, 4], [19, 9, 8, 69, 1396, 1397], [2, 42], [98, 21, 14], [582], [2, 296], [1, 74, 48, 225, 1398, 614, 423, 81, 388, 218], [1399, 59, 56], [47, 492, 50, 24, 42, 6, 27, 39, 54, 59, 1400, 103], [307, 193, 1401, 240, 609, 38, 234, 1, 114, 213, 1402, 1403], [126], [88, 15, 99, 1404, 229], [637, 1405, 1406, 1407, 647, 17, 37], [3, 93, 233], [159, 13, 16], [2, 214, 1408, 499, 230, 1409, 399, 196, 13, 1410, 1411, 230, 1412, 407], [13, 14, 536, 1413], [295], [14, 15, 203, 234], [2, 1], [47, 8, 1414, 112, 55, 56], [147, 631, 70, 1415, 1416, 35], [1417, 1418], [1419, 223, 417, 417], [4, 7, 266, 47, 47, 1420, 141, 94, 649, 310, 89, 138, 79], [282], [122, 1421, 137, 136, 1422, 1423, 18, 225, 60, 624, 2], [4, 3, 70], [20, 2, 296], [2, 20], [623, 142, 149], [1424, 1425, 330, 172, 31], [3], [37, 374, 1426, 4, 296, 391, 1, 174, 501, 187], [49, 6, 19], [1427, 285], [100, 289, 1, 3, 11, 650, 4, 49, 219, 1428, 651, 186, 1429], [1430, 362, 222], [3, 46], [8, 52, 69, 153, 66], [104, 603, 27, 12, 11], [8, 69], [1431, 1432, 118, 22, 228], [5, 560, 589], [18, 144, 100, 1], [211], [15, 21], [267, 1433], [306, 1, 71, 30, 224, 102, 400, 342, 421, 246, 11], [297, 63, 1, 68, 10], [179, 354, 39, 39, 632, 10, 605, 302], [1434, 13, 283], [206, 17, 32, 616], [4, 1435], [4, 14], [3], [22, 4, 5], [300, 3], [158, 120, 163, 58, 84, 13], [343, 38], [1436, 174, 8, 567], [111, 12, 574, 180, 244, 10, 93, 369, 10], [26, 167, 1, 180, 87, 108, 165, 64, 610, 554, 1437], [126, 126, 646], [16, 152, 281], [1438, 648, 1439, 390, 652, 138, 573, 202], [47, 152, 63, 1, 93, 291, 1440], [15, 106, 66, 1441, 61, 109, 28, 377, 112], [228, 54, 1442], [95, 41, 636, 1443], [5, 149, 139, 72, 192, 653, 52, 408, 1444, 13], [96], [148, 299, 402], [51, 1445], [283, 28, 193], [4, 72, 20], [47, 58, 547, 52], [44, 30], [19, 214, 231, 618, 1, 556, 654], [1446, 301, 23], [5, 452, 221, 105, 1447, 12, 424], [46, 127], [3], [53, 1448], [3], [106, 85, 8, 167, 157, 553, 1449, 1450, 168, 1451], [95, 5, 57, 36], [78, 17, 287], [57, 36], [65, 35, 16, 215], [93, 65, 4], [14, 25, 218, 630, 85, 655, 82, 1452, 43, 652, 85, 655, 1], [15, 21, 34], [264, 6, 48, 2, 9, 4, 76, 4, 275, 1453], [30, 14, 119, 4, 127], [34, 164, 1454], [22, 4, 65, 383, 25, 212, 6, 40], [3, 70], [164, 6, 4, 17, 55], [210, 1455, 50, 240, 11, 1456, 1457, 411, 493, 392], [1458, 10, 32, 31], [4, 7], [65, 64, 56, 59, 112], [19, 1459, 533, 6], [19], [3, 600, 466, 304], [259, 142, 534, 612, 229, 1460, 422, 656], [1461, 186, 234, 321, 107, 1462, 415], [333, 76], [4, 54, 27, 271, 123, 12], [566, 38], [420, 422, 50, 394, 65], [638, 8, 243, 613, 62, 404], [161, 190, 155, 1463, 12, 1464, 1465], [25, 6, 40], [1466, 315, 202, 195, 262], [136, 273, 96, 286, 1467, 1468, 243, 63, 312, 657, 13], [414, 110, 7, 658, 514, 371, 9, 107], [27, 271, 177, 158, 236, 357, 505], [19, 5, 20], [61, 49], [5, 207, 7, 634, 178], [153, 46, 12], [2, 1], [38, 5, 659], [101, 5, 409, 37], [420, 58, 62, 45, 607, 602, 227, 129, 189, 658, 26, 124, 545, 118], [1469, 1470, 37, 537, 660, 227, 221, 247], [95, 1, 1471], [1472, 92, 627, 169], [31, 276, 13, 10, 6, 1473, 186, 63], [23, 12, 628, 59, 288, 1474, 233, 244], [517, 4, 154, 112, 85, 24, 44], [423, 347, 14, 1475, 7, 11, 280, 530, 340, 1476, 1477, 1478, 5], [562], [79, 544, 41, 526, 43, 173, 1479, 1480], [285, 559, 201, 81, 465, 1481], [4, 643, 183], [47, 1482, 1483, 36], [239, 425, 24, 426, 426, 426, 9, 96, 144, 358], [572], [1, 649, 661, 2, 661, 208, 1, 355, 1484, 1485, 583, 1486, 306], [106, 8, 1, 173, 125, 650, 1487], [1488, 1489, 1490, 629, 125, 191, 1491, 72, 1492, 233, 644, 167], [1493, 1494, 1495, 1496], [3], [1497, 1498, 73, 128], [81, 39, 238, 232, 14], [32, 33, 23], [55, 65], [102, 1], [3, 4], [67, 396, 74, 124, 7, 42, 6, 75], [1499, 243, 1, 43, 163, 227, 651, 58], [2, 15, 22, 21], [24, 292, 179, 42, 405], [306, 91, 149], [117, 74], [316, 162, 64, 40, 9, 542], [282, 288, 1500], [52, 304, 564, 1], [18, 309, 129, 645, 26, 18, 425], [111, 48, 1501, 189, 18, 1502, 1503, 1504, 87, 131, 165, 1505, 191, 26], [256, 593, 151, 1506, 436, 1, 133], [6, 1507, 1508, 55, 56], [484, 42, 6], [16, 1509, 662, 1510, 12, 298, 656], [94, 315, 1511, 4, 1], [122, 151, 406, 332, 3, 70], [245, 608, 76, 153, 110], [577], [500, 243, 406, 1512], [45, 133, 41, 76, 663, 153, 1513], [1514, 48, 1515, 47, 662, 284], [1516, 45, 569, 13, 80, 9], [30, 269], [56, 198, 14], [1517, 13], [81, 90, 150], [1518], [52], [1, 18, 47, 96, 664], [92, 123], [575, 1519, 568, 24, 96, 664], [31, 2, 1520], [22, 16, 5, 67, 1521, 1522, 12, 73, 245], [111, 351, 419, 456, 1523, 409, 92], [588, 380, 1524, 1525, 91, 55, 344], [97, 20, 14], [32, 24, 292, 99], [13, 5, 1526, 663, 1527, 94, 207, 1528, 1529, 1530, 3, 2], [91, 45], [242, 24, 26, 1531, 191], [111, 1532, 1533, 17, 1, 1534, 16, 657, 1], [335, 1535, 313], [150, 52, 1536, 1537, 60, 410, 412, 125], [395, 222, 412], [391, 140, 1538, 54, 35], [19, 5], [357, 73, 233, 244], [1539, 5], [1, 176, 238, 101, 659, 586, 1], [25, 29, 1540, 381, 317], [1541, 1], [399, 29, 259, 3, 70], [27, 1542, 12, 1543, 43, 132, 51, 9, 39, 1544, 12, 1545], [72, 76], [622, 23, 1546], [50, 106, 421, 17, 7, 53], [57, 36], [155, 37, 1547, 301, 5], [611, 1548, 72, 192, 653], [81, 1549, 1, 1550, 25, 279], [32, 242, 106, 85, 14, 1551, 1552], [1, 268, 244], [3, 89, 79, 115], [1553, 1554, 118, 22, 1555, 13], [22, 90, 29, 3], [1556, 12], [1557, 10, 68, 1558], [90], [213, 1559, 166], [87, 18, 1560, 244, 413, 12, 293], [73, 128, 660, 26, 1], [34, 346, 85], [54, 1561, 1562, 621, 1563, 1564], [654, 26, 113, 117, 35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Each sentence contains different number of words so we need padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_size=60\n",
        "X=pad_sequences(encoded_text,maxlen=max_size,padding='post')\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zKwNJxVp_4u",
        "outputId": "a7417952-ff62-43eb-e0a8-eb9822234056"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   4,   14,   19, ...,    0,    0,    0],\n",
              "       [   2,  311,    0, ...,    0,    0,    0],\n",
              "       [ 665,   29,  185, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  34,  346,   85, ...,    0,    0,    0],\n",
              "       [  54, 1561, 1562, ...,    0,    0,    0],\n",
              "       [ 654,   26,  113, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After padding \n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLdafSg0p_eN",
        "outputId": "31b0fdfe-e6c1-4a1b-921c-0b7ab99261f2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GLOVE VECTOR"
      ],
      "metadata": {
        "id": "bbDplRPPsrrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors=dict()"
      ],
      "metadata": {
        "id": "jiwdrk-kzt9x"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Extract glove model from preexisting twitter glove model\n",
        "file=open('glove.twitter.27B.25d.txt',encoding='utf-8')\n",
        "for line in file:\n",
        "  values=line.split()\n",
        "  word=values[0]\n",
        "  vectors=np.asarray(values[1:])\n",
        "  glove_vectors[word]=vectors\n",
        "file.close()  "
      ],
      "metadata": {
        "id": "G-KmH_E9sawd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "+len(glove_vectors.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMzwLwjKsauG",
        "outputId": "b639485a-9854-4f31-e833-953ed32ebfec"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1193514"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector_matrix=np.zeros((vocab_size,25))\n",
        "for word,index in token.word_index.items():\n",
        "  vector=glove_vectors.get(word)\n",
        "  if vector is not None:\n",
        "    word_vector_matrix[index]=vector\n",
        "  else:\n",
        "    print(word)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAxmkrhBsarV",
        "outputId": "688bee53-df7c-4edc-ff00-75986e234138"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eargels\n",
            "unacceptible\n",
            "highy\n",
            "bluetooths\n",
            "purcashed\n",
            "disapoinment\n",
            "reccomendation\n",
            "bougth\n",
            "bluetoooth\n",
            "earbugs\n",
            "excrutiatingly\n",
            "contstruct\n",
            "ngage\n",
            "riingtones\n",
            "frequentyly\n",
            "applifies\n",
            "comparably\n",
            "cingulair\n",
            "hoursthe\n",
            "thereplacement\n",
            "earpad\n",
            "accessoryone\n",
            "motorolas\n",
            "palmtop\n",
            "sturdiness\n",
            "incrediable\n",
            "earset\n",
            "wirefly\n",
            "plantronincs\n",
            "comfortible\n",
            "replacementr\n",
            "bitpim\n",
            "flipphones\n",
            "startac\n",
            "krussel\n",
            "tracfonewebsite\n",
            "toactivate\n",
            "blueant\n",
            "supertooth\n",
            "reoccure\n",
            "securly\n",
            "travled\n",
            "bottowm\n",
            "accessable\n",
            "satisifed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL BUILDING"
      ],
      "metadata": {
        "id": "E_3LNseN2_EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ZilgtS2-py",
        "outputId": "30b4bde1-8315-439b-bbb5-587dc7316b6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   4,   14,   19, ...,    0,    0,    0],\n",
              "       [   2,  311,    0, ...,    0,    0,    0],\n",
              "       [ 665,   29,  185, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  34,  346,   85, ...,    0,    0,    0],\n",
              "       [  54, 1561, 1562, ...,    0,    0,    0],\n",
              "       [ 654,   26,  113, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2,stratify=y)"
      ],
      "metadata": {
        "id": "ECkuiEOPsao5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation,Dropout,LSTM,Bidirectional,SpatialDropout1D,SimpleRNN\n",
        "#from tensorflow.keras.layers import Conv1D,MaxPooling1D,GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "QGEevcry5gil"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec_size=25\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,vec_size,input_length=max_size,weights=[word_vector_matrix],trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100,dropout=0.3,recurrent_dropout=0.3,return_sequences=True))\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128,return_sequences=True,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "model.add(Conv1D(64,8,activation='relu'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\"\"\"\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train,epochs=30,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi18ElQMsamO",
        "outputId": "052eaf03-51ef-4b4c-ba59-82c4ede859f0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 12s 362ms/step - loss: 0.6945 - accuracy: 0.5018 - val_loss: 0.6888 - val_accuracy: 0.5697\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 8s 335ms/step - loss: 0.6756 - accuracy: 0.5890 - val_loss: 0.6757 - val_accuracy: 0.5568\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 9s 379ms/step - loss: 0.6811 - accuracy: 0.5576 - val_loss: 0.6677 - val_accuracy: 0.5919\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 9s 359ms/step - loss: 0.7298 - accuracy: 0.6004 - val_loss: 0.6812 - val_accuracy: 0.5446\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 8s 337ms/step - loss: 0.6948 - accuracy: 0.5773 - val_loss: 0.6771 - val_accuracy: 0.5958\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 8s 332ms/step - loss: 0.6758 - accuracy: 0.5968 - val_loss: 0.6601 - val_accuracy: 0.6351\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 9s 344ms/step - loss: 0.6500 - accuracy: 0.6500 - val_loss: 0.5998 - val_accuracy: 0.7250\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 8s 326ms/step - loss: 0.6372 - accuracy: 0.6549 - val_loss: 0.6423 - val_accuracy: 0.6802\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 8s 336ms/step - loss: 0.6318 - accuracy: 0.6864 - val_loss: 0.5905 - val_accuracy: 0.7455\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 8s 339ms/step - loss: 0.6362 - accuracy: 0.6615 - val_loss: 0.6753 - val_accuracy: 0.5998\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 10s 392ms/step - loss: 0.6696 - accuracy: 0.6235 - val_loss: 0.6080 - val_accuracy: 0.6911\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 9s 353ms/step - loss: 0.6503 - accuracy: 0.6742 - val_loss: 0.6203 - val_accuracy: 0.6997\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 9s 345ms/step - loss: 0.6379 - accuracy: 0.6532 - val_loss: 0.5783 - val_accuracy: 0.7427\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 9s 349ms/step - loss: 0.6148 - accuracy: 0.6759 - val_loss: 0.5763 - val_accuracy: 0.7539\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 10s 393ms/step - loss: 0.6696 - accuracy: 0.6272 - val_loss: 0.6548 - val_accuracy: 0.6119\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 8s 339ms/step - loss: 0.6528 - accuracy: 0.6283 - val_loss: 0.6424 - val_accuracy: 0.6299\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 9s 340ms/step - loss: 0.6340 - accuracy: 0.6469 - val_loss: 0.6050 - val_accuracy: 0.6767\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 9s 359ms/step - loss: 0.6257 - accuracy: 0.6613 - val_loss: 0.5871 - val_accuracy: 0.7182\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 9s 343ms/step - loss: 0.6465 - accuracy: 0.6298 - val_loss: 0.6397 - val_accuracy: 0.6159\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 10s 389ms/step - loss: 0.6348 - accuracy: 0.6311 - val_loss: 0.5742 - val_accuracy: 0.7303\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 9s 348ms/step - loss: 0.6084 - accuracy: 0.6911 - val_loss: 0.5762 - val_accuracy: 0.7207\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 9s 341ms/step - loss: 0.6415 - accuracy: 0.6578 - val_loss: 0.6105 - val_accuracy: 0.7109\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 8s 337ms/step - loss: 0.6144 - accuracy: 0.6951 - val_loss: 0.5632 - val_accuracy: 0.7642\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 8s 328ms/step - loss: 0.5917 - accuracy: 0.7109 - val_loss: 0.5391 - val_accuracy: 0.7713\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 8s 336ms/step - loss: 0.6125 - accuracy: 0.6891 - val_loss: 0.5607 - val_accuracy: 0.7492\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 8s 326ms/step - loss: 0.6203 - accuracy: 0.6626 - val_loss: 0.5768 - val_accuracy: 0.7247\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 8s 326ms/step - loss: 0.6100 - accuracy: 0.6875 - val_loss: 0.5508 - val_accuracy: 0.7636\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 9s 376ms/step - loss: 0.6069 - accuracy: 0.6902 - val_loss: 0.5567 - val_accuracy: 0.7459\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 9s 343ms/step - loss: 0.5881 - accuracy: 0.7070 - val_loss: 0.5307 - val_accuracy: 0.7632\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 8s 338ms/step - loss: 0.6189 - accuracy: 0.6768 - val_loss: 0.5555 - val_accuracy: 0.7448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0596b03ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_lstm = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score_lstm[0])\n",
        "print('Test accuracy:', score_lstm[1])"
      ],
      "metadata": {
        "id": "W15CeWRa1yjm",
        "outputId": "50a3b70e-5e49-4003-ff93-aff029794cd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5555012226104736\n",
            "Test accuracy: 0.7448332905769348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_size=25\n",
        "model1=Sequential()\n",
        "model1.add(Embedding(vocab_size,vec_size,input_length=max_size,weights=[word_vector_matrix],trainable=False))\n",
        "model1.add(SpatialDropout1D(0.3))\n",
        "model1.add(Bidirectional(LSTM(100,dropout=0.3,recurrent_dropout=0.3,return_sequences=True)))\n",
        "model1.add(Dense(1024,activation='relu'))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Bidirectional(LSTM(128,return_sequences=True,activation='relu')))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train,y_train,epochs=30,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "B2-OYJp69MLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1d4da0-088f-4713-a98a-6da514e3eca7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 23s 664ms/step - loss: 0.6967 - accuracy: 0.5140 - val_loss: 0.6925 - val_accuracy: 0.5398\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.6727 - accuracy: 0.6058 - val_loss: 0.6283 - val_accuracy: 0.6840\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 16s 626ms/step - loss: 0.6476 - accuracy: 0.6430 - val_loss: 0.5771 - val_accuracy: 0.7295\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 17s 674ms/step - loss: 0.6157 - accuracy: 0.6801 - val_loss: 0.5982 - val_accuracy: 0.7064\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 16s 636ms/step - loss: 0.6101 - accuracy: 0.6737 - val_loss: 0.5724 - val_accuracy: 0.7604\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.6231 - accuracy: 0.6767 - val_loss: 0.5622 - val_accuracy: 0.7402\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 16s 631ms/step - loss: 0.5900 - accuracy: 0.7031 - val_loss: 0.5376 - val_accuracy: 0.7562\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 17s 670ms/step - loss: 0.5954 - accuracy: 0.6945 - val_loss: 0.5938 - val_accuracy: 0.7150\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.5928 - accuracy: 0.7053 - val_loss: 0.5194 - val_accuracy: 0.7803\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 16s 635ms/step - loss: 0.5942 - accuracy: 0.7087 - val_loss: 0.5243 - val_accuracy: 0.7793\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 16s 636ms/step - loss: 0.6509 - accuracy: 0.6522 - val_loss: 0.5471 - val_accuracy: 0.7485\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 16s 643ms/step - loss: 0.5847 - accuracy: 0.7028 - val_loss: 0.5213 - val_accuracy: 0.7457\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 17s 690ms/step - loss: 0.5735 - accuracy: 0.7113 - val_loss: 0.5012 - val_accuracy: 0.7835\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 16s 650ms/step - loss: 0.6259 - accuracy: 0.6766 - val_loss: 0.5388 - val_accuracy: 0.7593\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 16s 655ms/step - loss: 0.6123 - accuracy: 0.6989 - val_loss: 0.5514 - val_accuracy: 0.7757\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 17s 664ms/step - loss: 0.5541 - accuracy: 0.7405 - val_loss: 0.5290 - val_accuracy: 0.7682\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.5727 - accuracy: 0.7100 - val_loss: 0.5261 - val_accuracy: 0.7522\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 17s 660ms/step - loss: 0.5264 - accuracy: 0.7482 - val_loss: 0.5098 - val_accuracy: 0.7598\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 16s 636ms/step - loss: 0.5689 - accuracy: 0.7271 - val_loss: 0.5051 - val_accuracy: 0.7845\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 16s 646ms/step - loss: 0.5231 - accuracy: 0.7469 - val_loss: 0.4965 - val_accuracy: 0.7884\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.5546 - accuracy: 0.7281 - val_loss: 0.5028 - val_accuracy: 0.7910\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 17s 669ms/step - loss: 0.5232 - accuracy: 0.7464 - val_loss: 0.4730 - val_accuracy: 0.7845\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 16s 638ms/step - loss: 0.4968 - accuracy: 0.7698 - val_loss: 0.4853 - val_accuracy: 0.7755\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.5477 - accuracy: 0.7242 - val_loss: 0.4830 - val_accuracy: 0.7922\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.5226 - accuracy: 0.7463 - val_loss: 0.4497 - val_accuracy: 0.8150\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 16s 631ms/step - loss: 0.5381 - accuracy: 0.7441 - val_loss: 0.4853 - val_accuracy: 0.7747\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 17s 674ms/step - loss: 0.5063 - accuracy: 0.7551 - val_loss: 0.4709 - val_accuracy: 0.7763\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.5493 - val_accuracy: 0.7268\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.5421 - accuracy: 0.7360 - val_loss: 0.4730 - val_accuracy: 0.8027\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 16s 644ms/step - loss: 0.5382 - accuracy: 0.7169 - val_loss: 0.4892 - val_accuracy: 0.7686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0595846990>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_bilstm = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score_bilstm[0])\n",
        "print('Test accuracy:', score_bilstm[1])"
      ],
      "metadata": {
        "id": "0zpl0MQf9MEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4331ffb1-0027-471b-cc4c-7def9f612415"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.4891940653324127\n",
            "Test accuracy: 0.7685832977294922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_size=25\n",
        "model2=Sequential()\n",
        "model2.add(Embedding(vocab_size,vec_size,input_length=max_size,weights=[word_vector_matrix],trainable=False))\n",
        "model2.add(SpatialDropout1D(0.3))\n",
        "model2.add(SimpleRNN(100,dropout=0.3,recurrent_dropout=0.3,return_sequences=True))\n",
        "model2.add(Dense(1024,activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(SimpleRNN(128,return_sequences=True,activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train,y_train,epochs=30,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "BX5ANOnz7Kca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50a2918-0bd0-4470-ebe4-5c37e4966769"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 18s 668ms/step - loss: 0.6995 - accuracy: 0.5064 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 4s 148ms/step - loss: 0.6944 - accuracy: 0.5044 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 4s 141ms/step - loss: 0.6935 - accuracy: 0.5005 - val_loss: 0.6902 - val_accuracy: 0.5940\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6936 - accuracy: 0.4931 - val_loss: 0.6896 - val_accuracy: 0.5247\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6925 - accuracy: 0.5041 - val_loss: 0.6802 - val_accuracy: 0.5443\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6917 - accuracy: 0.5166 - val_loss: 0.6548 - val_accuracy: 0.7097\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6928 - accuracy: 0.5049 - val_loss: 0.6804 - val_accuracy: 0.5433\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6873 - accuracy: 0.5486 - val_loss: 0.5799 - val_accuracy: 0.7507\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6810 - accuracy: 0.5970 - val_loss: 0.6581 - val_accuracy: 0.6438\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6804 - accuracy: 0.5891 - val_loss: 0.6417 - val_accuracy: 0.6907\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 3s 127ms/step - loss: 0.6634 - accuracy: 0.6176 - val_loss: 0.6106 - val_accuracy: 0.7051\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6780 - accuracy: 0.6128 - val_loss: 0.6338 - val_accuracy: 0.6737\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6673 - accuracy: 0.6199 - val_loss: 0.6344 - val_accuracy: 0.6687\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 3s 128ms/step - loss: 0.6546 - accuracy: 0.6488 - val_loss: 0.6210 - val_accuracy: 0.6919\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6595 - accuracy: 0.6332 - val_loss: 0.6296 - val_accuracy: 0.6607\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.6596 - accuracy: 0.6226 - val_loss: 0.6403 - val_accuracy: 0.6368\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 3s 138ms/step - loss: 0.6597 - accuracy: 0.6146 - val_loss: 0.6700 - val_accuracy: 0.5913\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6526 - accuracy: 0.6143 - val_loss: 0.6637 - val_accuracy: 0.5887\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 3s 135ms/step - loss: 0.6700 - accuracy: 0.5811 - val_loss: 0.6591 - val_accuracy: 0.5973\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6556 - accuracy: 0.6201 - val_loss: 0.6590 - val_accuracy: 0.6043\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6565 - accuracy: 0.6128 - val_loss: 0.6582 - val_accuracy: 0.6052\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6464 - accuracy: 0.6202 - val_loss: 0.6645 - val_accuracy: 0.5914\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6722 - accuracy: 0.6043 - val_loss: 0.6482 - val_accuracy: 0.6198\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6641 - accuracy: 0.6118 - val_loss: 0.6335 - val_accuracy: 0.6604\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 0.6523 - accuracy: 0.6297 - val_loss: 0.6484 - val_accuracy: 0.6160\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 3s 132ms/step - loss: 0.6468 - accuracy: 0.6372 - val_loss: 0.6220 - val_accuracy: 0.6694\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 3s 129ms/step - loss: 0.6275 - accuracy: 0.6806 - val_loss: 0.5941 - val_accuracy: 0.7138\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.6595 - accuracy: 0.6311 - val_loss: 0.6112 - val_accuracy: 0.7239\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 3s 130ms/step - loss: 0.6504 - accuracy: 0.6531 - val_loss: 0.5846 - val_accuracy: 0.7382\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 3s 131ms/step - loss: 0.6684 - accuracy: 0.6181 - val_loss: 0.6031 - val_accuracy: 0.7408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0594334b90>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_rnn= model2.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score_rnn[0])\n",
        "print('Test accuracy:', score_rnn[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMFkAUAGUPY-",
        "outputId": "c4ebff5e-ee3b-4bd3-de4d-5bfe6c3c6256"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6031020879745483\n",
            "Test accuracy: 0.7407500743865967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " \n",
        "  \n",
        "# creating the dataset\n",
        "data = {'LSTM':score_lstm[0]*100, 'BI-LSTM':score_bilstm[0]*100,\"RNN\":score_rnn[0]*100}\n",
        "\n",
        "Algorithm = list(data.keys())\n",
        "LOSS = list(data.values())\n",
        "\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "\n",
        "plt.bar(Algorithm,LOSS, color ='maroon',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Algorithm\")\n",
        "plt.ylabel(\"LOSS_rating\")\n",
        "plt.title(\"Algorithm vs LOSS Graph inWord2Vec\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "OoVVeDfWVJR0",
        "outputId": "c5dbfe63-8ed0-48ab-990d-af9135f02ef2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1={'LSTM':score_lstm[1]*100, 'BI-LSTM':score_bilstm[1]*100,\"RNN\":score_rnn[1]*100}\n",
        "Accuracy=list(data1.values())\n",
        "fig = plt.figure(figsize = (7, 5))\n",
        "\n",
        "plt.bar(Algorithm,Accuracy, color ='green',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Algorithm\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Algorithm vs Accuracy Graph inWord2Vec\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "BdJE9HBEj1nJ",
        "outputId": "0b70fb87-44c8-4442-9e00-52dc84f463cc"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dNGWI-MFlB_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Sentiment Analysis using Transfer Learning for Amazon Reviews (Model_2)(GLOVE+LSTM/BILSTM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}